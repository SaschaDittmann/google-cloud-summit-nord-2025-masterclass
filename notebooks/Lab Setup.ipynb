{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "GSQhkviL8N4D"
      },
      "id": "GSQhkviL8N4D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Remote Connection\n",
        "\n",
        "The CONNECTION resource is the secure, IAM-governed \"handshake\" between BigQuery and other Google Cloud services, most notably Vertex AI and Google Cloud Storage.\n",
        "\n",
        "When a connection is created, it is associated with a unique service account. This service account acts as a proxy for BigQuery, and it must be granted the appropriate IAM roles to interact with external services. For instance, to call a Vertex AI model, the connection's service account needs the\n",
        "Vertex AI User (roles/aiplatform.user) role.\n",
        "\n",
        "This mechanism ensures that all interactions are authenticated, authorized, and auditable, adhering to the principle of least privilege and satisfying enterprise security requirements"
      ],
      "metadata": {
        "id": "TdqsTFEH8U97"
      },
      "id": "TdqsTFEH8U97"
    },
    {
      "cell_type": "code",
      "source": [
        "!bq mk --connection --location=US \\\n",
        "    --project_id=$GOOGLE_CLOUD_PROJECT \\\n",
        "    --connection_type=CLOUD_RESOURCE masterclass"
      ],
      "metadata": {
        "id": "x-bo7lTfxNZy"
      },
      "id": "x-bo7lTfxNZy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SERVICE_ACCT = !bq show --format=prettyjson --connection $GOOGLE_CLOUD_PROJECT.us.masterclass | grep \"serviceAccountId\" | cut -d '\"' -f 4\n",
        "SERVICE_ACCT_EMAIL = SERVICE_ACCT[-1]\n",
        "print(SERVICE_ACCT_EMAIL)"
      ],
      "metadata": {
        "id": "QE8pD2ojMetF"
      },
      "id": "QE8pD2ojMetF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "!gcloud projects add-iam-policy-binding --format=none --condition=None $PROJECT_ID --member=serviceAccount:$SERVICE_ACCT_EMAIL --role=roles/aiplatform.user"
      ],
      "metadata": {
        "id": "hKy37Xj2M0Q6"
      },
      "id": "hKy37Xj2M0Q6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud projects get-iam-policy $PROJECT_ID --flatten=bindings --filter=bindings.members:serviceAccount:$SERVICE_ACCT_EMAIL --format='value(bindings.role)'"
      ],
      "metadata": {
        "id": "nWMQ0EvXbSAy"
      },
      "id": "nWMQ0EvXbSAy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset & Register Models\n",
        "\n",
        "The remote model is the primary abstraction layer that makes in-database AI possible. Using a standard CREATE MODEL statement with a REMOTE WITH CONNECTION clause, a data engineer can register an externally hosted model as a callable object within a BigQuery dataset.\n",
        "\n",
        "This remote model can point to a powerful foundation model hosted on Vertex AI, such as Google's Gemini family or partner models from Anthropic and Mistral AI, or even a custom-trained model deployed on a Vertex AI Endpoint.\n",
        "\n",
        "The significance of this abstraction cannot be overstated. It transforms what would otherwise be a complex programming task—involving setting up a development environment, using a client library, managing API keys, and handling HTTP requests—into a simple, familiar SQL function call like ML.GENERATE_TEXT or ML.PREDICT.\n",
        "\n",
        "![GenAI Workflow](https://cloud.google.com/static/bigquery/images/gen-ai-workflow.png)\n",
        "\n",
        "The data engineer operates entirely within the BigQuery environment, while the platform handles the underlying mechanics of invoking the model, passing the data, and returning the results. This is the core mechanism that \"brings the model to the data,\" eliminating the need for complex MLOps pipelines for a wide range of use cases."
      ],
      "metadata": {
        "id": "IBFQa3uR8fX1"
      },
      "id": "IBFQa3uR8fX1"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "CREATE SCHEMA IF NOT EXISTS masterclass\n",
        "OPTIONS (\n",
        "    description = 'Data Lakehouse Mastery masterclass at the Google Cloud Summit North 2025 in Germany',\n",
        "    location = 'US');"
      ],
      "metadata": {
        "id": "Qm_TLFP3h6Zo"
      },
      "id": "Qm_TLFP3h6Zo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "masterclass/Lab 1 - Multimodal Data Enrichment.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}